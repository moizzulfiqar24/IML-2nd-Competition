{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.stats import skew\n",
    "from sklearn.decomposition import PCA\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import PowerTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../train.csv')\n",
    "test = pd.read_csv('../test.csv')\n",
    "testOriginal = pd.read_csv('../test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181507, 272)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop('row ID', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>SubArea Removal<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop('sub_area', axis=1, inplace=True)\n",
    "train.drop('sub_area', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Categorical To Numerical<h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Label<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train)\n",
    "test = pd.get_dummies(test)\n",
    "\n",
    "# categorical_columns = train.select_dtypes(include=['object']).columns.tolist()\n",
    "# print(\"Train: Categorical columns:\", categorical_columns)\n",
    "\n",
    "# label_encoder = LabelEncoder()\n",
    "\n",
    "# for column in categorical_columns:\n",
    "#     train[column] = label_encoder.fit_transform(train[column])\n",
    "\n",
    "# categorical_columns_test = test.select_dtypes(include=['object']).columns.tolist()\n",
    "# print(\"Test: Categorical columns:\", categorical_columns_test)\n",
    "\n",
    "# label_encoder = LabelEncoder()\n",
    "\n",
    "# for column in categorical_columns_test:\n",
    "#     test[column] = label_encoder.fit_transform(test[column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Working<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.loc[:, train.columns != 'price_doc']\n",
    "y = train[['price_doc']]\n",
    "\n",
    "# scaler = RobustScaler()\n",
    "# X = scaler.fit_transform(X)\n",
    "# test = scaler.transform(test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181507, 287)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77789, 287)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Forward Feature Selection<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = X[['full_sq', 'floor', 'build_count_monolith', 'industrial_km', 'trc_sqm_500',\n",
    " 'mosque_count_500', 'leisure_count_500', 'office_sqm_1000',\n",
    " 'cafe_count_1000_price_high', 'leisure_count_1000', 'power_transmission_line_km', \n",
    " 'big_market_km', 'public_healthcare_km', 'workplaces_km']]\n",
    "test2 = test[['full_sq', 'floor', 'build_count_monolith', 'industrial_km', 'trc_sqm_500',\n",
    " 'mosque_count_500', 'leisure_count_500', 'office_sqm_1000',\n",
    " 'cafe_count_1000_price_high', 'leisure_count_1000', 'power_transmission_line_km', \n",
    " 'big_market_km', 'public_healthcare_km', 'workplaces_km']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Min_Max Scaling<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X3 = scaler.fit_transform(X2)\n",
    "test3 = scaler.transform(test2)  \n",
    "\n",
    "pca = PCA(n_components=10)\n",
    "principalComponents = pca.fit_transform(X3)\n",
    "X3 = pd.DataFrame(data = principalComponents)\n",
    "\n",
    "pca2 = PCA(n_components=10)\n",
    "principalComponents = pca2.fit_transform(test3)\n",
    "test3 = pd.DataFrame(data = principalComponents)\n",
    "\n",
    "\n",
    "poly = PolynomialFeatures(2)\n",
    "X3 = poly.fit_transform(X3)\n",
    "test3 = poly.fit_transform(test3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Applying Model<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181507, 66)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77789, 66)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [ 0.00000000e+00  8.90504004e+06 -4.82768126e+06 -7.08340240e+05\n",
      " -5.75894596e+05  2.03369789e+06 -1.67996826e+06 -3.58097000e+06\n",
      " -5.08618418e+05 -1.35621738e+06 -4.58079891e+05 -5.01287555e+05\n",
      "  6.63278246e+05  7.39515969e+04  9.33559150e+04 -3.59965276e+05\n",
      "  2.75288134e+05  5.27889890e+05  8.32931879e+04  1.65041090e+05\n",
      "  5.55150952e+04 -2.90676485e+05 -1.22242317e+05 -1.72464319e+05\n",
      " -3.52363046e+05  4.62990131e+05 -1.61084157e+05 -2.32519458e+04\n",
      " -5.20045573e+03  1.09182817e+05 -8.85266249e+04  9.84355468e+04\n",
      "  1.56233603e+05 -2.60812298e+05 -6.48198681e+04  8.14591611e+04\n",
      " -1.21333842e+05 -1.09311490e+03  2.37476077e+05 -1.08579722e+05\n",
      "  1.07382615e+05  2.24172452e+05  1.36399729e+05 -1.24273639e+05\n",
      "  7.68239661e+04  1.02689779e+05  5.01493743e+04  3.89027112e+05\n",
      "  1.91309211e+05  6.44881053e+04  1.24153772e+05  2.76945915e+05\n",
      " -2.45299342e+04  2.18166986e+05  9.37098745e+03  2.17149250e+04\n",
      " -5.04991363e+05 -6.99112567e+05 -5.82423392e+05  2.26555079e+05\n",
      " -1.09680058e+05 -2.59756430e+05  1.16476256e+05 -1.85733842e+04\n",
      "  2.27536545e+05  1.12798203e+05]\n",
      "Intercept: [19297979.03180084]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Create and train the Lasso regression model\n",
    "alpha_value = 0.5  # You can adjust the alpha parameter based on your needs\n",
    "lasso_reg = Lasso(alpha=alpha_value, random_state=42)\n",
    "lasso_reg.fit(X3, y)\n",
    "\n",
    "# Print the coefficients and intercept\n",
    "print(\"Coefficients:\", lasso_reg.coef_)\n",
    "print(\"Intercept:\", lasso_reg.intercept_)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_lasso = lasso_reg.predict(test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the predictions to a CSV file\n",
    "result_df_lasso = pd.DataFrame({'row ID': testOriginal['row ID'], 'price_doc': y_pred_lasso.flatten()})\n",
    "result_df_lasso.to_csv('Day_6_Abdullah_Maqsood_24448_Submission_10.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
