{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.stats import skew\n",
    "from sklearn.decomposition import PCA\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../../2nd-Comp-Data/train.csv')\n",
    "test = pd.read_csv('../../2nd-Comp-Data/test.csv')\n",
    "testOriginal = pd.read_csv('../../2nd-Comp-Data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181507, 272)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop('row ID', axis=1, inplace=True)\n",
    "test.drop('sub_area', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('sub_area', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Categorical To Numerical<h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>OneHot<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train)\n",
    "test = pd.get_dummies(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Label<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical_columns = train.select_dtypes(include=['object']).columns.tolist()\n",
    "# print(\"Train: Categorical columns:\", categorical_columns)\n",
    "\n",
    "# label_encoder = LabelEncoder()\n",
    "\n",
    "# for column in categorical_columns:\n",
    "#     train[column] = label_encoder.fit_transform(train[column])\n",
    "\n",
    "# categorical_columns_test = test.select_dtypes(include=['object']).columns.tolist()\n",
    "# print(\"Test: Categorical columns:\", categorical_columns_test)\n",
    "\n",
    "# label_encoder = LabelEncoder()\n",
    "\n",
    "# for column in categorical_columns_test:\n",
    "#     test[column] = label_encoder.fit_transform(test[column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Scaling<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check_scaling_needed(dataframe, threshold=5):\n",
    "#     \"\"\"\n",
    "#     Identify columns in a pandas DataFrame that may require scaling.\n",
    "\n",
    "#     Parameters:\n",
    "#     - dataframe: pandas DataFrame\n",
    "#     - threshold: Range threshold to determine if a column requires scaling (default is 5)\n",
    "\n",
    "#     Returns:\n",
    "#     - List of tuples containing (column_name, range_value) for columns that may require scaling.\n",
    "#     \"\"\"\n",
    "#     scaling_needed_columns = []\n",
    "\n",
    "#     for column in dataframe.columns:\n",
    "#         if dataframe[column].dtype in ['int64', 'float64']:\n",
    "#             column_range = dataframe[column].max() - dataframe[column].min()\n",
    "#             if column_range > threshold:\n",
    "#                 scaling_needed_columns.append((column, column_range))\n",
    "\n",
    "#     return scaling_needed_columns\n",
    "\n",
    "# scaling_needed_columns = check_scaling_needed(train)\n",
    "\n",
    "# if not scaling_needed_columns:\n",
    "#     print(\"No columns require scaling.\")\n",
    "# else:\n",
    "#     print(\"Columns that may require scaling:\")\n",
    "#     for column, column_range in scaling_needed_columns:\n",
    "#         print(f\"{column}: Range = {column_range}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling_needed_columns = check_scaling_needed(train)\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "# for column, _ in scaling_needed_columns:\n",
    "#     if train[column].dtype in ['int64', 'float64']:\n",
    "#         train[column] = scaler.fit_transform(train[[column]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Normalization<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_skewed_columns(dataframe, threshold=0.5):\n",
    "#     \"\"\"\n",
    "#     Identify skewed columns in a pandas DataFrame.\n",
    "\n",
    "#     Parameters:\n",
    "#     - dataframe: pandas DataFrame\n",
    "#     - threshold: Skewness threshold to determine if a column is skewed (default is 0.5)\n",
    "\n",
    "#     Returns:\n",
    "#     - List of tuples containing (column_name, skewness_value) for skewed columns.\n",
    "#     \"\"\"\n",
    "#     skewed_columns = []\n",
    "    \n",
    "#     for column in dataframe.columns:\n",
    "#         if dataframe[column].dtype in ['int64', 'float64']:\n",
    "#             skewness = skew(dataframe[column])\n",
    "#             if abs(skewness) > threshold:\n",
    "#                 skewed_columns.append((column, skewness))\n",
    "    \n",
    "#     return skewed_columns\n",
    "\n",
    "# skewed_columns = find_skewed_columns(train)\n",
    "\n",
    "# if not skewed_columns:\n",
    "#     print(\"No skewed columns found.\")\n",
    "# else:\n",
    "#     print(\"Skewed columns:\")\n",
    "#     for column, skewness in skewed_columns:\n",
    "#         print(f\"{column}: Skewness = {skewness}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for column, _ in skewed_columns:\n",
    "#     if train[column].dtype in ['int64', 'float64']:\n",
    "#         train[column] = train[column].apply(lambda x: 1 if x == 0 else np.log(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Working<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.loc[:, train.columns != 'price_doc']\n",
    "y = train[['price_doc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181507, 287)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77789, 287)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>PCA<h3> \n",
    "<h5><i>Remember to set X2 & test2<i><h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = PCA(n_components=287)\n",
    "# principalComponents = pca.fit_transform(X)\n",
    "# X2 = pd.DataFrame(data = principalComponents)\n",
    "\n",
    "# pca2 = PCA(n_components=287)\n",
    "# principalComponents = pca2.fit_transform(test)\n",
    "# test2 = pd.DataFrame(data = principalComponents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #plot an elbow graph to find the optimal number of components\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.plot(pca.explained_variance_ratio_)\n",
    "# plt.xlabel('number of components')\n",
    "# plt.ylabel('cumulative explained variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ols_reg = LinearRegression()\n",
    "# sfs = SequentialFeatureSelector(ols_reg, direction='forward',n_features_to_select=5)\n",
    "# sfs.fit(X, y)\n",
    "# print(sfs.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X[['full_sq', 'mosque_count_500', 'leisure_count_500', 'cafe_count_1000_price_high', 'leisure_count_1000']]\n",
    "# test = test[['full_sq', 'mosque_count_500', 'leisure_count_500', 'cafe_count_1000_price_high', 'leisure_count_1000']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Forward Feature Selection<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ols_reg = LinearRegression()\n",
    "# sfs = SequentialFeatureSelector(ols_reg, direction='forward',n_features_to_select=15)\n",
    "# sfs.fit(X, y)\n",
    "# print(sfs.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X2 = X[['full_sq', 'mosque_count_500', 'leisure_count_500', 'cafe_count_1000_price_high', 'leisure_count_1000']]\n",
    "# test2 = test[['full_sq', 'mosque_count_500', 'leisure_count_500', 'cafe_count_1000_price_high', 'leisure_count_1000']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>P-Value Selection<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_significant_columns(df, target_variable_name):\n",
    "#     # Initialize lists to store column names and corresponding p-values\n",
    "#     significant_columns = []\n",
    "#     p_values = []\n",
    "\n",
    "#     # Loop through each column in the DataFrame\n",
    "#     for column in df.columns:\n",
    "#         # Skip the target variable itself\n",
    "#         if column == target_variable_name:\n",
    "#             continue\n",
    "        \n",
    "#         # Add a constant term for the intercept\n",
    "#         X = sm.add_constant(df[column])\n",
    "        \n",
    "#         # Fit the linear regression model\n",
    "#         model = sm.OLS(df[target_variable_name], X).fit()\n",
    "        \n",
    "#         # Get the p-value for the coefficient of the predictor variable\n",
    "#         p_value = model.pvalues[1]\n",
    "        \n",
    "#         # Print information about the current column\n",
    "#         print(f\"{column}: p-value = {p_value}\")\n",
    "        \n",
    "#         # Check if the p-value is less than or equal to 0.05\n",
    "#         if p_value <= 0.05:\n",
    "#             significant_columns.append(column)\n",
    "#             p_values.append(p_value)\n",
    "\n",
    "#     # Print total significant columns\n",
    "#     print(\"\\nTotal columns with p-value <= 0.05:\", len(significant_columns))\n",
    "    \n",
    "#     # Print names of significant columns\n",
    "#     print(\"\\nColumns with p-value <= 0.05:\", significant_columns)\n",
    "    \n",
    "#     # Create a new DataFrame with only the significant columns\n",
    "#     df_significant = df[significant_columns]\n",
    "    \n",
    "#     return df_significant\n",
    "\n",
    "# # Example usage:\n",
    "# target_variable_name = 'price_doc'\n",
    "# X2 = find_significant_columns(train, target_variable_name)\n",
    "# print(\"\\nDataFrame with significant columns:\")\n",
    "# print(X2)\n",
    "\n",
    "# test2 = test[X2.columns]\n",
    "\n",
    "# X = X.astype(float)\n",
    "# X = sm.add_constant(X)\n",
    "# mod = sm.OLS(y, X)\n",
    "# res = mod.fit()\n",
    "# print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_sq: p-value = 0.0000\n",
      "life_sq: p-value = 0.0000\n",
      "floor: p-value = 0.0000\n",
      "area_m: p-value = 0.0000\n",
      "raion_popul: p-value = 0.0000\n",
      "green_zone_part: p-value = 0.0000\n",
      "indust_part: p-value = 0.0000\n",
      "children_preschool: p-value = 0.0000\n",
      "preschool_education_centers_raion: p-value = 0.0000\n",
      "children_school: p-value = 0.0000\n",
      "school_education_centers_raion: p-value = 0.0000\n",
      "school_education_centers_top_20_raion: p-value = 0.0000\n",
      "healthcare_centers_raion: p-value = 0.0000\n",
      "university_top_20_raion: p-value = 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sport_objects_raion: p-value = 0.0000\n",
      "additional_education_raion: p-value = 0.0000\n",
      "culture_objects_top_25_raion: p-value = 0.0000\n",
      "shopping_centers_raion: p-value = 0.0000\n",
      "office_raion: p-value = 0.0000\n",
      "full_all: p-value = 0.0000\n",
      "male_f: p-value = 0.0000\n",
      "female_f: p-value = 0.0000\n",
      "young_all: p-value = 0.0000\n",
      "young_male: p-value = 0.0000\n",
      "young_female: p-value = 0.0000\n",
      "work_all: p-value = 0.0000\n",
      "work_male: p-value = 0.0000\n",
      "work_female: p-value = 0.0000\n",
      "ekder_all: p-value = 0.0000\n",
      "ekder_male: p-value = 0.0000\n",
      "ekder_female: p-value = 0.0000\n",
      "0_6_all: p-value = 0.0000\n",
      "0_6_male: p-value = 0.0000\n",
      "0_6_female: p-value = 0.0000\n",
      "7_14_all: p-value = 0.0000\n",
      "7_14_male: p-value = 0.0000\n",
      "7_14_female: p-value = 0.0000\n",
      "0_17_all: p-value = 0.0000\n",
      "0_17_male: p-value = 0.0000\n",
      "0_17_female: p-value = 0.0000\n",
      "16_29_all: p-value = 0.0000\n",
      "16_29_male: p-value = 0.0000\n",
      "16_29_female: p-value = 0.0000\n",
      "0_13_all: p-value = 0.0000\n",
      "0_13_male: p-value = 0.0000\n",
      "0_13_female: p-value = 0.0000\n",
      "raion_build_count_with_material_info: p-value = 0.0000\n",
      "build_count_block: p-value = 0.0000\n",
      "build_count_wood: p-value = 0.0000\n",
      "build_count_frame: p-value = 0.0000\n",
      "build_count_brick: p-value = 0.0000\n",
      "build_count_monolith: p-value = 0.0000\n",
      "build_count_panel: p-value = 0.0000\n",
      "build_count_foam: p-value = 0.0000\n",
      "build_count_slag: p-value = 0.0000\n",
      "build_count_mix: p-value = 0.0000\n",
      "raion_build_count_with_builddate_info: p-value = 0.0000\n",
      "build_count_before_1920: p-value = 0.0000\n",
      "build_count_1921-1945: p-value = 0.0000\n",
      "build_count_1946-1970: p-value = 0.0000\n",
      "build_count_1971-1995: p-value = 0.0000\n",
      "build_count_after_1995: p-value = 0.0000\n",
      "ID_metro: p-value = 0.0000\n",
      "metro_min_avto: p-value = 0.0000\n",
      "metro_km_avto: p-value = 0.0000\n",
      "metro_min_walk: p-value = 0.0000\n",
      "metro_km_walk: p-value = 0.0000\n",
      "kindergarten_km: p-value = 0.0000\n",
      "school_km: p-value = 0.0000\n",
      "park_km: p-value = 0.0000\n",
      "green_zone_km: p-value = 0.0000\n",
      "industrial_km: p-value = 0.0000\n",
      "water_treatment_km: p-value = 0.0000\n",
      "cemetery_km: p-value = 0.0000\n",
      "incineration_km: p-value = 0.0000\n",
      "railroad_station_walk_km: p-value = 0.0000\n",
      "railroad_station_walk_min: p-value = 0.0000\n",
      "ID_railroad_station_walk: p-value = 0.0000\n",
      "railroad_station_avto_km: p-value = 0.0000\n",
      "railroad_station_avto_min: p-value = 0.0000\n",
      "ID_railroad_station_avto: p-value = 0.0000\n",
      "public_transport_station_km: p-value = 0.0000\n",
      "public_transport_station_min_walk: p-value = 0.0000\n",
      "water_km: p-value = 0.0000\n",
      "mkad_km: p-value = 0.0000\n",
      "ttk_km: p-value = 0.0000\n",
      "sadovoe_km: p-value = 0.0000\n",
      "bulvar_ring_km: p-value = 0.0000\n",
      "kremlin_km: p-value = 0.0000\n",
      "big_road1_km: p-value = 0.0000\n",
      "ID_big_road1: p-value = 0.0000\n",
      "big_road2_km: p-value = 0.0000\n",
      "ID_big_road2: p-value = 0.0000\n",
      "railroad_km: p-value = 0.0000\n",
      "zd_vokzaly_avto_km: p-value = 0.0000\n",
      "ID_railroad_terminal: p-value = 0.0000\n",
      "bus_terminal_avto_km: p-value = 0.0000\n",
      "ID_bus_terminal: p-value = 0.0000\n",
      "oil_chemistry_km: p-value = 0.0000\n",
      "nuclear_reactor_km: p-value = 0.0000\n",
      "radiation_km: p-value = 0.0000\n",
      "power_transmission_line_km: p-value = 0.0000\n",
      "thermal_power_plant_km: p-value = 0.0000\n",
      "ts_km: p-value = 0.0000\n",
      "big_market_km: p-value = 0.0000\n",
      "market_shop_km: p-value = 0.0000\n",
      "fitness_km: p-value = 0.0000\n",
      "swim_pool_km: p-value = 0.0000\n",
      "ice_rink_km: p-value = 0.0000\n",
      "stadium_km: p-value = 0.0000\n",
      "basketball_km: p-value = 0.0000\n",
      "hospice_morgue_km: p-value = 0.0000\n",
      "detention_facility_km: p-value = 0.0000\n",
      "public_healthcare_km: p-value = 0.0000\n",
      "university_km: p-value = 0.0000\n",
      "workplaces_km: p-value = 0.0000\n",
      "shopping_centers_km: p-value = 0.0000\n",
      "office_km: p-value = 0.0000\n",
      "additional_education_km: p-value = 0.0000\n",
      "preschool_km: p-value = 0.0000\n",
      "big_church_km: p-value = 0.0000\n",
      "church_synagogue_km: p-value = 0.0000\n",
      "mosque_km: p-value = 0.0000\n",
      "theater_km: p-value = 0.0000\n",
      "museum_km: p-value = 0.0000\n",
      "exhibition_km: p-value = 0.0000\n",
      "catering_km: p-value = 0.0000\n",
      "green_part_500: p-value = 0.0000\n",
      "prom_part_500: p-value = 0.0000\n",
      "office_count_500: p-value = 0.0000\n",
      "office_sqm_500: p-value = 0.0000\n",
      "trc_count_500: p-value = 0.0000\n",
      "trc_sqm_500: p-value = 0.0000\n",
      "cafe_count_500: p-value = 0.0000\n",
      "cafe_count_500_na_price: p-value = 0.0000\n",
      "cafe_count_500_price_500: p-value = 0.0000\n",
      "cafe_count_500_price_1000: p-value = 0.0000\n",
      "cafe_count_500_price_1500: p-value = 0.0000\n",
      "cafe_count_500_price_2500: p-value = 0.0000\n",
      "cafe_count_500_price_4000: p-value = 0.0000\n",
      "cafe_count_500_price_high: p-value = 0.0000\n",
      "big_church_count_500: p-value = 0.0000\n",
      "church_count_500: p-value = 0.0000\n",
      "mosque_count_500: p-value = 0.0000\n",
      "leisure_count_500: p-value = 0.0000\n",
      "sport_count_500: p-value = 0.0000\n",
      "market_count_500: p-value = 0.0000\n",
      "green_part_1000: p-value = 0.0000\n",
      "prom_part_1000: p-value = 0.0000\n",
      "office_count_1000: p-value = 0.0000\n",
      "office_sqm_1000: p-value = 0.0000\n",
      "trc_count_1000: p-value = 0.0000\n",
      "trc_sqm_1000: p-value = 0.0000\n",
      "cafe_count_1000: p-value = 0.0000\n",
      "cafe_count_1000_na_price: p-value = 0.0000\n",
      "cafe_count_1000_price_500: p-value = 0.0000\n",
      "cafe_count_1000_price_1000: p-value = 0.0000\n",
      "cafe_count_1000_price_1500: p-value = 0.0000\n",
      "cafe_count_1000_price_2500: p-value = 0.0000\n",
      "cafe_count_1000_price_4000: p-value = 0.0000\n",
      "cafe_count_1000_price_high: p-value = 0.0000\n",
      "big_church_count_1000: p-value = 0.0000\n",
      "church_count_1000: p-value = 0.0000\n",
      "mosque_count_1000: p-value = 0.0000\n",
      "leisure_count_1000: p-value = 0.0000\n",
      "sport_count_1000: p-value = 0.0000\n",
      "market_count_1000: p-value = 0.0000\n",
      "green_part_1500: p-value = 0.0000\n",
      "prom_part_1500: p-value = 0.0000\n",
      "office_count_1500: p-value = 0.0000\n",
      "office_sqm_1500: p-value = 0.0000\n",
      "trc_count_1500: p-value = 0.0000\n",
      "trc_sqm_1500: p-value = 0.0000\n",
      "cafe_count_1500: p-value = 0.0000\n",
      "cafe_count_1500_na_price: p-value = 0.0000\n",
      "cafe_count_1500_price_500: p-value = 0.0000\n",
      "cafe_count_1500_price_1000: p-value = 0.0000\n",
      "cafe_count_1500_price_1500: p-value = 0.0000\n",
      "cafe_count_1500_price_2500: p-value = 0.0000\n",
      "cafe_count_1500_price_4000: p-value = 0.0000\n",
      "cafe_count_1500_price_high: p-value = 0.0000\n",
      "big_church_count_1500: p-value = 0.0000\n",
      "church_count_1500: p-value = 0.0000\n",
      "mosque_count_1500: p-value = 0.0000\n",
      "leisure_count_1500: p-value = 0.0000\n",
      "sport_count_1500: p-value = 0.0000\n",
      "market_count_1500: p-value = 0.0000\n",
      "green_part_2000: p-value = 0.0000\n",
      "prom_part_2000: p-value = 0.0000\n",
      "office_count_2000: p-value = 0.0000\n",
      "office_sqm_2000: p-value = 0.0000\n",
      "trc_count_2000: p-value = 0.0000\n",
      "trc_sqm_2000: p-value = 0.0000\n",
      "cafe_count_2000: p-value = 0.0000\n",
      "cafe_sum_2000_min_price_avg: p-value = 0.0000\n",
      "cafe_sum_2000_max_price_avg: p-value = 0.0000\n",
      "cafe_avg_price_2000: p-value = 0.0000\n",
      "cafe_count_2000_na_price: p-value = 0.0000\n",
      "cafe_count_2000_price_500: p-value = 0.0000\n",
      "cafe_count_2000_price_1000: p-value = 0.0000\n",
      "cafe_count_2000_price_1500: p-value = 0.0000\n",
      "cafe_count_2000_price_2500: p-value = 0.0000\n",
      "cafe_count_2000_price_4000: p-value = 0.0000\n",
      "cafe_count_2000_price_high: p-value = 0.0000\n",
      "big_church_count_2000: p-value = 0.0000\n",
      "church_count_2000: p-value = 0.0000\n",
      "mosque_count_2000: p-value = 0.0000\n",
      "leisure_count_2000: p-value = 0.0000\n",
      "sport_count_2000: p-value = 0.0000\n",
      "market_count_2000: p-value = 0.0000\n",
      "green_part_3000: p-value = 0.0000\n",
      "prom_part_3000: p-value = 0.0000\n",
      "office_count_3000: p-value = 0.0000\n",
      "office_sqm_3000: p-value = 0.0000\n",
      "trc_count_3000: p-value = 0.0000\n",
      "trc_sqm_3000: p-value = 0.0000\n",
      "cafe_count_3000: p-value = 0.0000\n",
      "cafe_sum_3000_min_price_avg: p-value = 0.0000\n",
      "cafe_sum_3000_max_price_avg: p-value = 0.0000\n",
      "cafe_avg_price_3000: p-value = 0.0000\n",
      "cafe_count_3000_na_price: p-value = 0.0000\n",
      "cafe_count_3000_price_500: p-value = 0.0000\n",
      "cafe_count_3000_price_1000: p-value = 0.0000\n",
      "cafe_count_3000_price_1500: p-value = 0.0000\n",
      "cafe_count_3000_price_2500: p-value = 0.0000\n",
      "cafe_count_3000_price_4000: p-value = 0.0000\n",
      "cafe_count_3000_price_high: p-value = 0.0000\n",
      "big_church_count_3000: p-value = 0.0000\n",
      "church_count_3000: p-value = 0.0000\n",
      "mosque_count_3000: p-value = 0.0000\n",
      "leisure_count_3000: p-value = 0.0000\n",
      "sport_count_3000: p-value = 0.0000\n",
      "market_count_3000: p-value = 0.0000\n",
      "green_part_5000: p-value = 0.0000\n",
      "prom_part_5000: p-value = 0.0000\n",
      "office_count_5000: p-value = 0.0000\n",
      "office_sqm_5000: p-value = 0.0000\n",
      "trc_count_5000: p-value = 0.0000\n",
      "trc_sqm_5000: p-value = 0.0000\n",
      "cafe_count_5000: p-value = 0.0000\n",
      "cafe_sum_5000_min_price_avg: p-value = 0.0000\n",
      "cafe_sum_5000_max_price_avg: p-value = 0.0000\n",
      "cafe_avg_price_5000: p-value = 0.0000\n",
      "cafe_count_5000_na_price: p-value = 0.0000\n",
      "cafe_count_5000_price_500: p-value = 0.0000\n",
      "cafe_count_5000_price_1000: p-value = 0.0000\n",
      "cafe_count_5000_price_1500: p-value = 0.0000\n",
      "cafe_count_5000_price_2500: p-value = 0.0000\n",
      "cafe_count_5000_price_4000: p-value = 0.0000\n",
      "cafe_count_5000_price_high: p-value = 0.0000\n",
      "big_church_count_5000: p-value = 0.0000\n",
      "church_count_5000: p-value = 0.0000\n",
      "mosque_count_5000: p-value = 0.0000\n",
      "leisure_count_5000: p-value = 0.0000\n",
      "sport_count_5000: p-value = 0.0000\n",
      "market_count_5000: p-value = 0.0000\n",
      "product_type_Investment: p-value = 0.0000\n",
      "product_type_OwnerOccupier: p-value = 0.0000\n",
      "culture_objects_top_25_no: p-value = 0.0000\n",
      "culture_objects_top_25_yes: p-value = 0.0000\n",
      "thermal_power_plant_raion_no: p-value = 0.0000\n",
      "thermal_power_plant_raion_yes: p-value = 0.0000\n",
      "incineration_raion_no: p-value = 0.0000\n",
      "incineration_raion_yes: p-value = 0.0000\n",
      "oil_chemistry_raion_no: p-value = 0.0000\n",
      "oil_chemistry_raion_yes: p-value = 0.0000\n",
      "radiation_raion_no: p-value = 0.0000\n",
      "radiation_raion_yes: p-value = 0.0000\n",
      "railroad_terminal_raion_no: p-value = 0.0000\n",
      "railroad_terminal_raion_yes: p-value = 0.0000\n",
      "big_market_raion_no: p-value = 0.0000\n",
      "big_market_raion_yes: p-value = 0.0000\n",
      "nuclear_reactor_raion_no: p-value = 0.0000\n",
      "nuclear_reactor_raion_yes: p-value = 0.0000\n",
      "detention_facility_raion_no: p-value = 0.0000\n",
      "detention_facility_raion_yes: p-value = 0.0000\n",
      "water_1line_no: p-value = 0.0000\n",
      "water_1line_yes: p-value = 0.0000\n",
      "big_road1_1line_no: p-value = 0.0000\n",
      "big_road1_1line_yes: p-value = 0.0000\n",
      "railroad_1line_no: p-value = 0.0000\n",
      "railroad_1line_yes: p-value = 0.0000\n",
      "ecology_excellent: p-value = 0.0000\n",
      "ecology_no data: p-value = 0.0000\n",
      "ecology_poor: p-value = 0.0000\n",
      "ecology_satisfactory: p-value = 0.0000\n",
      "\n",
      "Total columns with p-value <= 0.05: 286\n",
      "\n",
      "DataFrame with significant columns:\n",
      "        full_sq  life_sq  floor        area_m  raion_popul  green_zone_part  \\\n",
      "0          43.0     27.0    4.0  6.407578e+06     155572.0         0.189727   \n",
      "1          34.0     19.0    3.0  9.589337e+06     115352.0         0.372602   \n",
      "2          43.0     29.0    2.0  4.808270e+06     101708.0         0.112560   \n",
      "3          77.0     77.0    4.0  8.398461e+06     108171.0         0.015234   \n",
      "4          67.0     46.0   14.0  7.506452e+06      43795.0         0.007670   \n",
      "...         ...      ...    ...           ...          ...              ...   \n",
      "181502     48.0     33.0    3.0  6.455617e+07       4949.0         0.586175   \n",
      "181503     48.0     33.0    3.0  6.455617e+07       4949.0         0.586175   \n",
      "181504     48.0     33.0    3.0  6.455617e+07       4949.0         0.586175   \n",
      "181505     48.0     33.0    3.0  6.455617e+07       4949.0         0.586175   \n",
      "181506     48.0     33.0    3.0  6.455617e+07       4949.0         0.586175   \n",
      "\n",
      "        indust_part  children_preschool  preschool_education_centers_raion  \\\n",
      "0          0.000070              9576.0                                5.0   \n",
      "1          0.049637              6880.0                                5.0   \n",
      "2          0.118537              5879.0                                4.0   \n",
      "3          0.037316              5706.0                                7.0   \n",
      "4          0.486246              2418.0                                2.0   \n",
      "...             ...                 ...                                ...   \n",
      "181502     0.005819               346.0                                0.0   \n",
      "181503     0.005819               346.0                                0.0   \n",
      "181504     0.005819               346.0                                0.0   \n",
      "181505     0.005819               346.0                                0.0   \n",
      "181506     0.005819               346.0                                0.0   \n",
      "\n",
      "        children_school  ...  water_1line_no  water_1line_yes  \\\n",
      "0               10309.0  ...             1.0              0.0   \n",
      "1                7759.0  ...             1.0              0.0   \n",
      "2                6207.0  ...             1.0              0.0   \n",
      "3                6748.0  ...             1.0              0.0   \n",
      "4                2514.0  ...             1.0              0.0   \n",
      "...                 ...  ...             ...              ...   \n",
      "181502            342.0  ...             1.0              0.0   \n",
      "181503            342.0  ...             1.0              0.0   \n",
      "181504            342.0  ...             1.0              0.0   \n",
      "181505            342.0  ...             1.0              0.0   \n",
      "181506            342.0  ...             1.0              0.0   \n",
      "\n",
      "        big_road1_1line_no  big_road1_1line_yes  railroad_1line_no  \\\n",
      "0                      1.0                  0.0                1.0   \n",
      "1                      1.0                  0.0                1.0   \n",
      "2                      1.0                  0.0                1.0   \n",
      "3                      1.0                  0.0                0.0   \n",
      "4                      1.0                  0.0                1.0   \n",
      "...                    ...                  ...                ...   \n",
      "181502                 1.0                  0.0                1.0   \n",
      "181503                 1.0                  0.0                1.0   \n",
      "181504                 1.0                  0.0                1.0   \n",
      "181505                 1.0                  0.0                1.0   \n",
      "181506                 1.0                  0.0                1.0   \n",
      "\n",
      "        railroad_1line_yes  ecology_excellent  ecology_no data  ecology_poor  \\\n",
      "0                      0.0                0.0              0.0           0.0   \n",
      "1                      0.0                1.0              0.0           0.0   \n",
      "2                      0.0                0.0              0.0           1.0   \n",
      "3                      1.0                1.0              0.0           0.0   \n",
      "4                      0.0                0.0              0.0           1.0   \n",
      "...                    ...                ...              ...           ...   \n",
      "181502                 0.0                0.0              1.0           0.0   \n",
      "181503                 0.0                0.0              1.0           0.0   \n",
      "181504                 0.0                0.0              1.0           0.0   \n",
      "181505                 0.0                0.0              1.0           0.0   \n",
      "181506                 0.0                0.0              1.0           0.0   \n",
      "\n",
      "        ecology_satisfactory  \n",
      "0                        0.0  \n",
      "1                        0.0  \n",
      "2                        0.0  \n",
      "3                        0.0  \n",
      "4                        0.0  \n",
      "...                      ...  \n",
      "181502                   0.0  \n",
      "181503                   0.0  \n",
      "181504                   0.0  \n",
      "181505                   0.0  \n",
      "181506                   0.0  \n",
      "\n",
      "[181507 rows x 286 columns]\n"
     ]
    }
   ],
   "source": [
    "def find_significant_columns(X, y):\n",
    "    # Convert the entire DataFrame to float\n",
    "    X = X.astype(float)\n",
    "\n",
    "    significant_columns = []\n",
    "\n",
    "    for column in X.columns:\n",
    "        if X[column].dtype == float:  # Only consider float columns\n",
    "            X_with_constant = sm.add_constant(X[column])\n",
    "            model = sm.OLS(y, X_with_constant).fit()\n",
    "            p_value = model.pvalues[1]  # Extract the p-value for the independent variable\n",
    "\n",
    "            if p_value <= 0.05:\n",
    "                significant_columns.append(column)\n",
    "                print(f\"{column}: p-value = {p_value:.4f}\")\n",
    "\n",
    "    print(\"\\nTotal columns with p-value <= 0.05:\", len(significant_columns))\n",
    "\n",
    "    # Create a new DataFrame with only significant columns\n",
    "    significant_df = X[significant_columns]\n",
    "\n",
    "    return significant_df\n",
    "\n",
    "X2 = find_significant_columns(X, y)\n",
    "print(\"\\nDataFrame with significant columns:\")\n",
    "print(X2)\n",
    "\n",
    "test2 = test[X2.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Applying Model<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181507, 286)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77789, 286)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reg2 = LinearRegression().fit(X_train, y_train)\n",
    "# y_pred = reg2.predict(X_test)\n",
    "# print(\"LR: R2 = %.4f and MSE = %.2f\" % (reg2.score(X_test,y_test), mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reg2 = LinearRegression().fit(X_train, y_train)\n",
    "# y_pred = reg2.predict(X_test)\n",
    "# print(\"LR: R2 = %.4f and MSE = %.2f\" % (reg2.score(X_test,y_test), mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg2 = LinearRegression().fit(X2, y)\n",
    "y_pred = reg2.predict(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame({'row ID': testOriginal['row ID'], 'price_doc': y_pred.flatten()})\n",
    "result_df.to_csv('Day2.8.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
