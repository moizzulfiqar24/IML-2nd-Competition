{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "train_data = pd.read_csv('../../2nd-Comp-Data/train.csv')\n",
    "test_data = pd.read_csv('../../2nd-Comp-Data/test.csv')\n",
    "\n",
    "used = []\n",
    "\n",
    "# Extract features and target variable\n",
    "X = train_data.drop('price_doc', axis=1)\n",
    "y = train_data['price_doc']\n",
    "X_test = test_data.drop(['row ID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = pd.get_dummies(X)\n",
    "# X_test = pd.get_dummies(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all columns in X_train with dtypes object\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'object':\n",
    "        X.drop(col, axis=1, inplace=True)\n",
    "\n",
    "# drop all columns in X_test with dtypes object\n",
    "for col in X_test.columns:\n",
    "    if X_test[col].dtype == 'object':\n",
    "        X_test.drop(col, axis=1, inplace=True)\n",
    "\n",
    "used.append(\"Removed Object Dtypes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "used.append(\"StandardScaler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "used.append(\"Keras With Torch Backend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "81/81 [==============================] - 2s 22ms/step - loss: 692468249001984.0000 - val_loss: 701411310436352.0000\n",
      "Epoch 2/100\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 692244642267136.0000 - val_loss: 700921952600064.0000\n",
      "Epoch 3/100\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 691306795892736.0000 - val_loss: 699395494379520.0000\n",
      "Epoch 4/100\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 689040663773184.0000 - val_loss: 696238492090368.0000\n",
      "Epoch 5/100\n",
      "81/81 [==============================] - 1s 14ms/step - loss: 684888571248640.0000 - val_loss: 690936757616640.0000\n",
      "Epoch 6/100\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 678399546753024.0000 - val_loss: 683022139523072.0000\n",
      "Epoch 7/100\n",
      "81/81 [==============================] - 1s 14ms/step - loss: 669111747084288.0000 - val_loss: 672150973317120.0000\n",
      "Epoch 8/100\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 656872164032512.0000 - val_loss: 658142534828032.0000\n",
      "Epoch 9/100\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 641366728114176.0000 - val_loss: 640857573163008.0000\n",
      "Epoch 10/100\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 622618591887360.0000 - val_loss: 620352124223488.0000\n",
      "Epoch 11/100\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 600670906351616.0000 - val_loss: 596468146634752.0000\n",
      "Epoch 12/100\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 575542596206592.0000 - val_loss: 569739826954240.0000\n",
      "Epoch 13/100\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 548204458278912.0000 - val_loss: 540513111375872.0000\n",
      "Epoch 14/100\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 517904168648704.0000 - val_loss: 509299033899008.0000\n",
      "Epoch 15/100\n",
      "81/81 [==============================] - 1s 12ms/step - loss: 486436721655808.0000 - val_loss: 476750765096960.0000\n",
      "Epoch 16/100\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 454249934749696.0000 - val_loss: 443547748663296.0000\n",
      "Epoch 17/100\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 421630195007488.0000 - val_loss: 410498143092736.0000\n",
      "Epoch 18/100\n",
      "81/81 [==============================] - 1s 14ms/step - loss: 389314458419200.0000 - val_loss: 378365076832256.0000\n",
      "Epoch 19/100\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 358940718137344.0000 - val_loss: 347725082132480.0000\n",
      "Epoch 20/100\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 330345899622400.0000 - val_loss: 319332361961472.0000\n",
      "Epoch 21/100\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 304196863655936.0000 - val_loss: 293754925744128.0000\n",
      "Epoch 22/100\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 281426641551360.0000 - val_loss: 271180879626240.0000\n",
      "Epoch 23/100\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 260656968237056.0000 - val_loss: 252002693021696.0000\n",
      "Epoch 24/100\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 244254286807040.0000 - val_loss: 236027897708544.0000\n",
      "Epoch 25/100\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 230711197958144.0000 - val_loss: 223179939250176.0000\n",
      "Epoch 26/100\n",
      "81/81 [==============================] - 1s 14ms/step - loss: 219939856187392.0000 - val_loss: 213283747397632.0000\n",
      "Epoch 27/100\n",
      "81/81 [==============================] - 1s 12ms/step - loss: 212781370441728.0000 - val_loss: 205794935046144.0000\n",
      "Epoch 28/100\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 207361004273664.0000 - val_loss: 200350476795904.0000\n",
      "Epoch 29/100\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 202790169214976.0000 - val_loss: 196435496665088.0000\n",
      "Epoch 30/100\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 201459283001344.0000 - val_loss: 193777314562048.0000\n",
      "Epoch 31/100\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 198992294051840.0000 - val_loss: 191900111863808.0000\n",
      "Epoch 32/100\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 197834213163008.0000 - val_loss: 190640495263744.0000\n",
      "Epoch 33/100\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 196686785806336.0000 - val_loss: 189649163124736.0000\n",
      "Epoch 34/100\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 196462256324608.0000 - val_loss: 188977134960640.0000\n",
      "Epoch 35/100\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 196300289081344.0000 - val_loss: 188458903535616.0000\n",
      "Epoch 36/100\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 195584002621440.0000 - val_loss: 188013065797632.0000\n",
      "Epoch 37/100\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 195172860166144.0000 - val_loss: 187614153932800.0000\n",
      "Epoch 38/100\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 195589992087552.0000 - val_loss: 187288524947456.0000\n",
      "Epoch 39/100\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 194446339604480.0000 - val_loss: 186967123820544.0000\n",
      "Epoch 40/100\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 194861156270080.0000 - val_loss: 186694477283328.0000\n",
      "Epoch 41/100\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 194321986879488.0000 - val_loss: 186400607567872.0000\n",
      "Epoch 42/100\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 193766728138752.0000 - val_loss: 186122709762048.0000\n",
      "Epoch 43/100\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 194021305614336.0000 - val_loss: 185902458470400.0000\n",
      "Epoch 44/100\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 192960968785920.0000 - val_loss: 185647646113792.0000\n",
      "Epoch 45/100\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 192990043701248.0000 - val_loss: 185412513431552.0000\n",
      "Epoch 46/100\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 193554412470272.0000 - val_loss: 185198721368064.0000\n",
      "Epoch 47/100\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 192341788852224.0000 - val_loss: 184987060011008.0000\n",
      "Epoch 48/100\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 192342208282624.0000 - val_loss: 184796034629632.0000\n",
      "Epoch 49/100\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 192666629308416.0000 - val_loss: 184601871908864.0000\n",
      "Epoch 50/100\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 192695888773120.0000 - val_loss: 184396451676160.0000\n",
      "Epoch 51/100\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 192500501315584.0000 - val_loss: 184193699020800.0000\n",
      "Epoch 52/100\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 191659425923072.0000 - val_loss: 183998244454400.0000\n",
      "Epoch 53/100\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 190801841750016.0000 - val_loss: 183795609239552.0000\n",
      "Epoch 54/100\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 191955594117120.0000 - val_loss: 183656459010048.0000\n",
      "Epoch 55/100\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 191478601089024.0000 - val_loss: 183482999373824.0000\n",
      "Epoch 56/100\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 191587216785408.0000 - val_loss: 183294943559680.0000\n",
      "Epoch 57/100\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 190969429360640.0000 - val_loss: 183106602532864.0000\n",
      "Epoch 58/100\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 190618399670272.0000 - val_loss: 182988558041088.0000\n",
      "Epoch 59/100\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 190653329833984.0000 - val_loss: 182855934148608.0000\n",
      "Epoch 60/100\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 191158122708992.0000 - val_loss: 182718813962240.0000\n",
      "Epoch 61/100\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 190021919309824.0000 - val_loss: 182554296582144.0000\n",
      "Epoch 62/100\n",
      "81/81 [==============================] - 2s 21ms/step - loss: 190679300964352.0000 - val_loss: 182421941125120.0000\n",
      "Epoch 63/100\n",
      "81/81 [==============================] - 2s 27ms/step - loss: 190046414045184.0000 - val_loss: 182244387848192.0000\n",
      "Epoch 64/100\n",
      "81/81 [==============================] - 2s 25ms/step - loss: 189878256009216.0000 - val_loss: 182122316824576.0000\n",
      "Epoch 65/100\n",
      "81/81 [==============================] - 2s 21ms/step - loss: 189388931727360.0000 - val_loss: 181972294959104.0000\n",
      "Epoch 66/100\n",
      "81/81 [==============================] - 2s 21ms/step - loss: 189009313660928.0000 - val_loss: 181859887611904.0000\n",
      "Epoch 67/100\n",
      "81/81 [==============================] - 2s 19ms/step - loss: 190029603274752.0000 - val_loss: 181768334344192.0000\n",
      "Epoch 68/100\n",
      "81/81 [==============================] - 2s 20ms/step - loss: 189735582564352.0000 - val_loss: 181624201281536.0000\n",
      "Epoch 69/100\n",
      "81/81 [==============================] - 1s 14ms/step - loss: 188709706137600.0000 - val_loss: 181512112701440.0000\n",
      "Epoch 70/100\n",
      "81/81 [==============================] - 1s 12ms/step - loss: 188999817756672.0000 - val_loss: 181401013977088.0000\n",
      "Epoch 71/100\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 189594687504384.0000 - val_loss: 181244818096128.0000\n",
      "Epoch 72/100\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 189644314509312.0000 - val_loss: 181188178214912.0000\n",
      "Epoch 73/100\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 189383344914432.0000 - val_loss: 181084662792192.0000\n",
      "Epoch 74/100\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 188950694068224.0000 - val_loss: 180987858255872.0000\n",
      "Epoch 75/100\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 189063017529344.0000 - val_loss: 180855083368448.0000\n",
      "Epoch 76/100\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 188885330034688.0000 - val_loss: 180740830527488.0000\n",
      "Epoch 77/100\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 188815050276864.0000 - val_loss: 180638892163072.0000\n",
      "Epoch 78/100\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 187917838319616.0000 - val_loss: 180561112989696.0000\n",
      "Epoch 79/100\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 187631283470336.0000 - val_loss: 180409715392512.0000\n",
      "Epoch 80/100\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 188140639748096.0000 - val_loss: 180319772737536.0000\n",
      "Epoch 81/100\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 188401659674624.0000 - val_loss: 180269021659136.0000\n",
      "Epoch 82/100\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 187194723532800.0000 - val_loss: 180136129331200.0000\n",
      "Epoch 83/100\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 187043929915392.0000 - val_loss: 180027530412032.0000\n",
      "Epoch 84/100\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 187732215201792.0000 - val_loss: 179939601022976.0000\n",
      "Epoch 85/100\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 187026582274048.0000 - val_loss: 179815869054976.0000\n",
      "Epoch 86/100\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 187802595622912.0000 - val_loss: 179779881926656.0000\n",
      "Epoch 87/100\n",
      "81/81 [==============================] - 1s 13ms/step - loss: 186856847179776.0000 - val_loss: 179664689561600.0000\n",
      "Epoch 88/100\n",
      "81/81 [==============================] - 1s 13ms/step - loss: 186547626311680.0000 - val_loss: 179605264662528.0000\n",
      "Epoch 89/100\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 186752090243072.0000 - val_loss: 179516261531648.0000\n",
      "Epoch 90/100\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 186537761308672.0000 - val_loss: 179437794492416.0000\n",
      "Epoch 91/100\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 186217182265344.0000 - val_loss: 179310304428032.0000\n",
      "Epoch 92/100\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 187565567115264.0000 - val_loss: 179319448010752.0000\n",
      "Epoch 93/100\n",
      "81/81 [==============================] - 1s 10ms/step - loss: 186544723853312.0000 - val_loss: 179215848701952.0000\n",
      "Epoch 94/100\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 187372914343936.0000 - val_loss: 179193199460352.0000\n",
      "Epoch 95/100\n",
      "81/81 [==============================] - 1s 12ms/step - loss: 186804703592448.0000 - val_loss: 179075960274944.0000\n",
      "Epoch 96/100\n",
      "81/81 [==============================] - 1s 12ms/step - loss: 186296102289408.0000 - val_loss: 179034772209664.0000\n",
      "Epoch 97/100\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 186220202164224.0000 - val_loss: 178962512740352.0000\n",
      "Epoch 98/100\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 186130041405440.0000 - val_loss: 178907416363008.0000\n",
      "Epoch 99/100\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 186478940389376.0000 - val_loss: 178810746044416.0000\n",
      "Epoch 100/100\n",
      "81/81 [==============================] - 1s 9ms/step - loss: 186291203342336.0000 - val_loss: 178752864649216.0000\n"
     ]
    }
   ],
   "source": [
    "features_used = X_train.shape[1]\n",
    "\n",
    "# Build the neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.3))  # You can use either dropout or early stopping\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation='linear'))  # Output layer with linear activation for regression\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=1800, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "\n",
    "used.append(\"2 Hidden Layers: Hidden Layer 1 with 128 neurons relu activation\\n, Hidden Layer 2 with 64 neurons relu activation, Dropout 0.3, O linear\")\n",
    "used.append(\"Adam Optimizer\")\n",
    "used.append(\"Loss Calculation: Mean Squared Error\")\n",
    "used.append(\"EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\")\n",
    "used.append(\"batch_size=1800, epochs=100, early_stopping, dropout=0.3 (used in hidden layers)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2431/2431 [==============================] - 2s 798us/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "submission_df = pd.DataFrame({'row ID': test_data['row ID'], 'price_doc': predictions.flatten()})\n",
    "\n",
    "# Save the results to a CSV file\n",
    "submission_df.to_csv('Day7.1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Used = 256\n",
      "\n",
      "Removed Object Dtypes\n",
      "StandardScaler\n",
      "Keras With Torch Backend\n",
      "Layers: H1 128 relu, H2 64 relu, Dropout 0.3, O linear\n",
      "Compiled with loss='mean_squared_error', optimizer='adam'\n",
      "EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
      "epochs=100, batch_size=1800\n"
     ]
    }
   ],
   "source": [
    "print(\"Features Used = \" + str(features_used) + \"\\n\")\n",
    "for i in used:\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
