{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.calibration import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training and testing datasets\n",
    "train_data = pd.read_csv('../../2nd-Comp-Data/train.csv')\n",
    "test_data = pd.read_csv('../../2nd-Comp-Data/test.csv')\n",
    "test_data.drop('row ID', axis=1, inplace=True)\n",
    "train_data.drop('sub_area', axis=1, inplace=True)\n",
    "test_data.drop('sub_area', axis=1, inplace=True)\n",
    "testOriginal = pd.read_csv('../../2nd-Comp-Data/test.csv')\n",
    "\n",
    "# Separate features and target variable in the training data\n",
    "X = train_data.drop('price_doc', axis=1)\n",
    "y = train_data['price_doc']\n",
    "\n",
    "X = X[['full_sq', 'floor', 'build_count_monolith', 'industrial_km', 'trc_sqm_500','mosque_count_500', 'leisure_count_500', 'office_sqm_1000', 'cafe_count_1000_price_high', 'leisure_count_1000', 'power_transmission_line_km', 'big_market_km', 'public_healthcare_km', 'workplaces_km', 'shopping_centers_raion', 'green_part_500']]\n",
    "test_data = test_data[['full_sq', 'floor', 'build_count_monolith', 'industrial_km', 'trc_sqm_500','mosque_count_500', 'leisure_count_500', 'office_sqm_1000', 'cafe_count_1000_price_high', 'leisure_count_1000', 'power_transmission_line_km', 'big_market_km', 'public_healthcare_km', 'workplaces_km', 'shopping_centers_raion', 'green_part_500']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "\n",
    "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Create transformers for numerical and categorical features\n",
    "numerical_transformer = RobustScaler()\n",
    "categorical_transformer = OneHotEncoder()\n",
    "\n",
    "# Combine transformers into a preprocessor using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create a pipeline with preprocessor and Lasso Regression model\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', Lasso(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.01, RMSE: 13717065.988925079\n",
      "Alpha: 0.1, RMSE: 13717065.989138473\n",
      "Alpha: 1, RMSE: 13717065.991200393\n",
      "Alpha: 10, RMSE: 13717066.013597135\n",
      "Alpha: 100, RMSE: 13717066.237570152\n",
      "Best Alpha Value: 0.01\n",
      "Root Mean Squared Error on validation set: 13774849.645387534\n"
     ]
    }
   ],
   "source": [
    "# Define alpha values for grid search\n",
    "alphas = [0.1, 0.3, 0.6, 0.7, 0.9]\n",
    "\n",
    "# Set up the parameter grid for grid search\n",
    "param_grid = {'regressor__alpha': alphas}\n",
    "\n",
    "# Use GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the results of grid search\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "# Print RMSE for each alpha value\n",
    "for index, row in results_df.iterrows():\n",
    "    alpha_value = row['param_regressor__alpha']\n",
    "    rmse = sqrt(-row['mean_test_score'])\n",
    "    print(f'Alpha: {alpha_value}, RMSE: {rmse}')\n",
    "\n",
    "# Print the best alpha value\n",
    "best_alpha = grid_search.best_params_['regressor__alpha']\n",
    "print(f'Best Alpha Value: {best_alpha}')\n",
    "\n",
    "# Get the best model from grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict the target variable on the validation set using the best model\n",
    "y_pred = best_model.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = sqrt(mean_squared_error(y_val, y_pred))\n",
    "print(f'Root Mean Squared Error on validation set: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy has not improved\n",
      "Previous: OneHot, MinMaxScaler\n"
     ]
    }
   ],
   "source": [
    "prevAcc = 13774849.645387534\n",
    "currAcc = rmse\n",
    "\n",
    "x = currAcc - prevAcc\n",
    "if x < 0:\n",
    "    print(\"Accuracy has improved\")\n",
    "    print(\"Current: OneHot, RobustScaler, Alpha = \" + str(best_alpha))\n",
    "else:\n",
    "    print(\"Accuracy has not improved\")\n",
    "    print(\"Previous: OneHot, RobustScaler, Alpha = 0.01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Features : 16\n",
      "Lasso Regression, Alpha = 0.01, Random State = 42\n"
     ]
    }
   ],
   "source": [
    "# Predictions on test data\n",
    "test_predictions = best_model.predict(test_data)\n",
    "result_df = pd.DataFrame({'row ID': testOriginal['row ID'], 'price_doc': test_predictions.flatten()})\n",
    "result_df.to_csv('Day5.1.csv', index=False)\n",
    "             \n",
    "# Check the shape of the validation set\n",
    "print(\"Total Features : \" + str(X_val.shape[1]))\n",
    "print(\"Lasso Regression, Alpha = \" + str(best_alpha) + \", Random State = 42\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alpha: 0.01, RMSE: 13717065.98890476. OneHot, StandardScaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
